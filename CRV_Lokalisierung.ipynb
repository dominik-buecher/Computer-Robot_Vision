{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer and Robot Vision project (Teil 1: Die Lokalisierung)\n",
    "\n",
    "In diesem Notebook geht es darum, wie wir Geschwindigkeitsschilder lokalisieren und klassifizieren können. Anders als üblich setzen wir dabei nicht auf herkömmliche Bildverarbeitung, sondern trainieren KI-Modelle, die diese Aufgaben eigenständig übernehmen können.\n",
    "\n",
    "Die Idee dahinter ist, das Projekt in zwei Teile aufzuteilen, die unabhängig voneinander funktionieren können. Ein Modell wird speziell darauf trainiert, die Schilder im Bild zu lokalisieren, während ein separates Modell nur für die Klassifizierung zuständig ist. Dieses Notebook konzentriert sich auf die Lokalisierung und gibt Einblicke in die Methoden und Erkenntnisse, die dabei zum Einsatz kommen.\n",
    "\n",
    "---\n",
    "\n",
    "**Author:**\n",
    "\n",
    "Dominik Bücher, Hochschuhle Heilbronn, Automotive System Engineering Master | dbuecher@stud.hs-heilbronn.de\n",
    "\n",
    "Aaron Kiani, Hochschuhle Heilbronn, Mechatronik und Robotik Master | akiani@stud.hs-heilbronn.de\n",
    "\n",
    "\n",
    "**Professor:**\n",
    "\n",
    "Prof. Dr. Dieter Maier \n",
    "\n",
    "dieter.maier@hs-heilbronn.de\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### 1. [Einleitung](#Introduction)\n",
    "#### 2. [Importieren der Bibliotheken](#Import)\n",
    "#### 3. [Erstellen eines eigenen Datensatzes](#Dataset)\n",
    "#### 4. [Training der Modelle](#modelle)\n",
    "#### 5. [Evaluation](#Evaluation)\n",
    "#### 6. [Testing](#Testing)\n",
    "#### 7. [Diskussion der Ergebnisse](#Diskussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einleitung <a id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im kommenden Kapitel wird zunächst die Struktur dieses Notebooks vorgestellt sowie das übergeordnete Ziel dieser Aufgabe erläutert.\n",
    "\n",
    "Wie bereits zu Beginn des Notebooks erwähnt, liegt der Fokus dieses Abschnitts auf der Lokalisierung von Geschwindigkeitsschilder. Hierbei stehen verschiedene Ansätze zur Verfügung, wobei wir uns für einen eher klassischen Weg entschieden haben: die Verwendung von Cascading-Modellen.\n",
    "\n",
    "Cascading-Modelle repräsentieren eine spezielle Klasse von Klassifikationsmodellen, die nicht nur auf dem etablierten \"Haar-like features\"-Ansatz basieren, sondern auch Local Binary Pattern (LBP) einbeziehen. Diese kombinierte Methode vereint die Effizienz der Haar-ähnlichen Merkmale mit der präzisen Texturerkennung von LBP, was eine vielseitige Lösung für die Objekterkennung in Bildern bietet. Der Begriff \"cascading\" (kaskadierend) leitet sich davon ab, dass diese Modelle hierarchisch angeordnete Kaskaden von Klassifikatoren nutzen.\n",
    "\n",
    "Die Grundidee der Cascading-Modelle besteht darin, hierarchisch angeordnete Kaskaden von Klassifikatoren zu verwenden. Jede Stufe dieser Kaskade filtert gezielt bestimmte Bildbereiche und leitet nur die vielversprechendsten Regionen an die nachfolgende Stufe weiter. Diese kaskadierende Struktur ermöglicht eine effiziente Ablehnung von irrelevanten Bereichen und konzentriert die Ressourcen auf vielversprechende Regionen, was insbesondere bei der Verarbeitung großer Bildmengen von Vorteil ist.\n",
    "\n",
    "Obwohl Cascading-Modelle ihre Bekanntheit hauptsächlich der Gesichtserkennung verdanken, eignen sie sich ebenso für die Erkennung anderer Objekte wie Geschwindigkeitsschilder oder Fahrzeuge. Der Trainingsprozess umfasst die Nutzung positiver und negativer Beispiele, um das Modell auf die spezifischen Mustererkennungsaufgaben anzupassen. Diese adaptive Anpassung ermöglicht eine präzise und effiziente Objekterkennung in verschiedenen Kontexten.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importieren der Bibliotheken <a id=\"Import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Erstellen eines eigenen Datensatzes <a id=\"Dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein Cascading-Modell erfolgreich zu trainieren, ist ein geeigneter Datensatz von entscheidender Bedeutung. Zu diesem Zweck wurden verschiedene Videos in und um Heilbronn aufgenommen. Die Aufnahmen erfolgten mit einer GoPro 11 unter den folgenden Einstellungen: 30 FPS (Bildern pro Sekunde) und einer Auflösung von 1920x1080 Pixel (HD).\n",
    "\n",
    "Die aufgenommenen Videos wurden anschließend mithilfe eines speziellen Skripts in Bilddateien umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_path, output_path):\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not video_capture.isOpened():\n",
    "        print(\"Fehler beim Öffnen des Videos.\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_filename = f\"frame_{frame_count:04d}.jpg\"\n",
    "        frame_path = os.path.join(output_path, frame_filename)\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        frame_count += 1\n",
    "    print(f\"{frame_count} Frames wurden erfolgreich extrahiert.\")\n",
    "    video_capture.release()\n",
    "\n",
    "\n",
    "video_path = r\"videos_24_11_2023\\video_speed_combined.mp4\"\n",
    "output_path = r\"videos_24_11_2023\\combined\"\n",
    "video_to_frames(video_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Umwandlung der Videos in Bilder ist es nun möglich, die einzelnen Bilder zu labeln, was von entscheidender Bedeutung ist, da ein Modell ohne diese Annotationen nicht trainiert werden kann.\n",
    "\n",
    "Der Kennzeichnungsprozess beinhaltete das Auffinden aller Geschwindigkeitsschilder in einem Bild und das Hinzufügen von Begrenzungsrahmen (Bounding Boxes) um diese. Es gibt verschiedene Programme, die für diese Aufgabe verwendet werden können, und wir haben uns für DarkLabel 2.4 entschieden. Dabei ist zu erwähnen das das Labeln sehr viel zeit in anspruch nehmen kann, wobei DarkLabel2.4 diese zeit zumindest etwas verkürzt hat. \n",
    "\n",
    "Nachdem alle Bilder erfolgreich gelabelt wurden, wird eine Textdatei generiert, die die Daten zu jeder einzelnen Bounding Box enthält. Diese Datei bildet die Grundlage für das spätere Training des Modells.\n",
    "\n",
    "Die Text Datei ist dabei wie folgt aufgebaut: 00000.jpg,1,795,428,50,49. Jedoch wird für das training ein Format wie dieses \"00000.jpg 1 795 428 50 49\" benötigt, bzw \"frame_3321.jpg 2 177 499 157 141 1692 577 103 93\" falls es zwei Bounding Boxen in einem Bild gibt. Zusätzlich dazu dürfen die Koordinaten nicht die Größe des Bildes überschreiten. All diese kleinen Änderungen werden in den nachfolgenden Funktionen behoben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_coordinates(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            parts = line.strip().split(' ')\n",
    "            if len(parts) == 6:\n",
    "                x_coordinate = int(parts[2])\n",
    "                width = int(parts[4])\n",
    "\n",
    "                # Überprüfe, ob die Koordinaten größer als 1919 sind\n",
    "                if x_coordinate > 1919 or (x_coordinate + width) > 1919:\n",
    "                    if x_coordinate > 1919:\n",
    "                        x_coordinate = 1919 - width\n",
    "                    if (x_coordinate + width) > 1919:\n",
    "                        width = 1919 - x_coordinate\n",
    "\n",
    "                # Überprüfe, ob die Koordinaten kleiner als 1 sind\n",
    "                if x_coordinate < 1 or (x_coordinate + width) < 1:\n",
    "                    if x_coordinate < 1:\n",
    "                        x_coordinate = 1\n",
    "                    if (x_coordinate + width) < 1:\n",
    "                        width = 1 - x_coordinate\n",
    "\n",
    "                # Erstelle die aktualisierte Zeile\n",
    "                updated_line = f\"{parts[0]},{parts[1]},{x_coordinate},{parts[3]},{width},{parts[5]}\\n\"\n",
    "                outfile.write(updated_line)\n",
    "            else:\n",
    "                # Schreibe Zeilen ohne das erwartete Format unverändert\n",
    "                outfile.write(line)\n",
    "\n",
    "\n",
    "def combine_lines(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        lines = infile.readlines()\n",
    "        i = 0\n",
    "        while i < len(lines) - 1:\n",
    "            current_line = lines[i].strip().split(';')\n",
    "            next_line = lines[i + 1].strip().split(';')\n",
    "\n",
    "            if current_line[0] == next_line[0]:\n",
    "                combined_line = [current_line[0], str(int(current_line[1]) + 1)] + [current_line[2]] + current_line[3:] + next_line[1:]\n",
    "                lines[i] = ' '.join(combined_line) + '\\n'\n",
    "                lines.pop(i + 1)\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        # Ersetze alle Kommas durch Leerzeichen in den verbleibenden Zeilen\n",
    "        for j in range(len(lines)):\n",
    "            lines[j] = lines[j].replace(';', ' ')\n",
    "\n",
    "        outfile.writelines(lines)\n",
    "\n",
    "\n",
    "\n",
    "adjust_coordinates(r'Dominik\\annotation_files\\train.txt', r'Dominik\\annotation_files\\train2.txt')\n",
    "combine_lines(r'Dominik\\gt copy2.txt', r'Dominik\\pos_new.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die Textdatei nun im korrekten Format vorliegt, schreiten wir zum nächsten Schritt: der Aufteilung des Datensatzes in Trainings- und Testbilder. Der folgende Code generiert zwei neue Textdateien für diese Aufteilung. Dabei werden die Daten zunächst zufällig durchmischt und anschließend aufgeteilt. Der Trainingsdatensatz umfasst dabei 95% der Bilder, während der Testdatensatz nur 5% enthält. Obwohl eine übliche Aufteilung 90 zu 10 wäre, haben wir uns aufgrund der begrenzten Anzahl von insgesamt 3726 Bildern entschieden, dem Training einen größeren Datensatzanteil zuzuweisen, wie in der folgenden Abbildung verdeutlicht wird:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Notebook_Bilder/Split_data.png\" width=\"500\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(input_datei, ausgabe_datei_1, ausgabe_datei_2, trennungsprozentsatz=5):\n",
    "    with open(input_datei, 'r') as datei:\n",
    "        zeilen = datei.readlines()\n",
    "    \n",
    "    random.shuffle(zeilen)\n",
    "    \n",
    "    trennungspunkt = int(len(zeilen) * (trennungsprozentsatz / 100))\n",
    "    ausgabe_1 = zeilen[:trennungspunkt]\n",
    "    ausgabe_2 = zeilen[trennungspunkt:]\n",
    "    \n",
    "    with open(ausgabe_datei_1, 'w') as datei_1:\n",
    "        datei_1.writelines(ausgabe_1)\n",
    "    \n",
    "    with open(ausgabe_datei_2, 'w') as datei_2:\n",
    "        datei_2.writelines(ausgabe_2)\n",
    "\n",
    "\n",
    "input_datei = r'Dominik\\annotation_files\\pos_own.txt'\n",
    "ausgabe_datei_1 = r'Dominik\\annotation_files\\test.txt'\n",
    "ausgabe_datei_2 = r'Dominik\\annotation_files\\train.txt'\n",
    "split_dataset(input_datei, ausgabe_datei_1, ausgabe_datei_2, trennungsprozentsatz=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die beiden Textdateien erstellt wurden, haben Sie die Möglichkeit, die Bilder in die entsprechenden Ordner zu verschieben. Obwohl dies nicht zwingend erforderlich ist, trägt es zur besseren Übersicht bei. Für das eigentliche Training muss die Textdatei der Trainingsdaten zwar erneut verarbeitet werden, doch dieser Schritt wird in einem späteren Kapitel ausführlich behandelt.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training der Modelle <a id=\"modelle\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie schon zuvor erwähnt werden für die Lokalisierung Cascaden Modelle verwendet. OpenCV stellt hierfür ein Programm zu verfügung um diese zu trainieren. Bei dem Training mit OpenCV ist es möglich zwischen zwei verschiedenen Cascaden Modellen zu wählen, dem \"Haar-like features\"-Ansatz oder dem Local Binary Pattern (LBP)-Ansatz. Diese beiden Varianten werden im folgenden kurz erläutert.\n",
    "\n",
    "**Haar Cascade:**     \n",
    "Haar Cascades sind eine Methode der Gesichts- und Objekterkennung, die auf der Analyse von Haar-ähnlichen Mustern basiert. Diese Modelle nutzen eine Kaskadenstruktur von Merkmalsklassifikatoren, wobei einfache Merkmale in den frühen Stadien für schnelle Ablehnungen verwendet werden und komplexere Merkmale in späteren Stadien für genauere Überprüfungen. Ein Nachteil von Haar Cascades kann ihre Empfindlichkeit gegenüber Variationen in Pose, Beleuchtung und Hintergrundbedingungen sein.\n",
    "\n",
    "**LBP Cascade:**   \n",
    "Local Binary Pattern (LBP) ist eine Methode zur Texturbeschreibung in Bildern. Sie erfasst lokale Muster, indem sie jeden Pixel mit seinen Nachbarn vergleicht und binäre Codes für lokale Muster erzeugt. LBP wird häufig in Gesichts- und Objekterkennungssystemen eingesetzt. Ein Nachteil von LBP besteht in seiner begrenzten Unterscheidungskraft, insbesondere in Szenarien mit geringem Kontrast oder komplexen Texturen. Trotzdem ist LBP eine effektive Methode zur Extraktion von Texturmerkmalen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Modelle nun trainineren zu können muss zunächst die opencv_traincascade.exe von OpenCV heruntergeladen werden. Mit diesem Programm ist es möglich die Modelle in der Kommandozeile zu trainieren. Wie ein solcher Befehlsaufruf aussehen könnte ist folgend dargestellt:\n",
    "\n",
    "C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/cascade_12/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 10 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType LBP\n",
    "\n",
    "Um zuverstehen wie sich dieser Befehl zusammensetz werden die Parameter kurz vorgestellt.\n",
    "1. Zunächst wird mit einem Pfad die ausführbare Datei von OpenCV verlinkt.\n",
    "2. -data gibt an wo das fertige Modell abegseichert werden soll.\n",
    "3. -vec gibt an wo sich die .vec Datei der Labels befindet. Diese wird mit der opencv_createsamples.exe und der zuvor konstruierten Text Datei erstellt.\n",
    "4. -bg gibt den Pfad zu der Text Datei an in der sich die Speicherorte für die Negativen Beispiele an.\n",
    "5. -precalcValBufSize und -precalcIdxBufSize reserviert Speicher für die Ausführung um so schneller arbeiten zu können. \n",
    "6. -w 24 -h 24 legt fest wie groß die kleinsten zu erkennenden Features in einem Bild sind, hier sind es 24 mal 24 Pixel.\n",
    "7. -numPos und -numNeg legen fest wieviel Positive Daten und wieviele Negative Daten für das Training verwendet werden.\n",
    "8. -numStages gibt die Anzahl an Epochen für das Training an.\n",
    "9. -maxFalseAlarmRate dieser Wert gibt an wie hoch der Prozentsatz für False-Psoitive Werte sein darf.\n",
    "10. -minHitRate gibt die minimale gewünschte Trefferquote für jede Stufe des Klassifikators an.\n",
    "11. -featureType wählt zum Schluss aus ob das Haar oder LBP Verfahren verwendet werden soll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training für 5 Epochen:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Training parameters are pre-loaded from the parameter file in data folder!\n",
      "Please empty this folder if you want to use a NEW set of training parameters.\n",
      "---------------------------------------------------------------------------------\n",
      "PARAMETERS:\n",
      "cascadeDirName: Dominik/models/cascade_12/\n",
      "vecFileName: dataset/positive_samples/train/train.vec\n",
      "bgFileName: dataset/negative_samples/neg2.txt\n",
      "numPos: 3500\n",
      "numNeg: 1750\n",
      "numStages: 10\n",
      "precalcValBufSize[Mb] : 16000\n",
      "precalcIdxBufSize[Mb] : 16000\n",
      "acceptanceRatioBreakValue : -1\n",
      "stageType: BOOST\n",
      "featureType: LBP\n",
      "sampleWidth: 24\n",
      "sampleHeight: 24\n",
      "boostType: GAB\n",
      "minHitRate: 0.999\n",
      "maxFalseAlarmRate: 0.05\n",
      "weightTrimRate: 0.95\n",
      "maxDepth: 1\n",
      "maxWeakCount: 100\n",
      "Number of unique features given windowSize [24,24] : 8464\n",
      "\n",
      "Stages 0-9 are loaded\n"
     ]
    }
   ],
   "source": [
    "# maxFalseAlarmRate = 0.1\n",
    "# Haar:\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_1750_01_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 5 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType HAAR\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_3500_01_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 3500 -numStages 5 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType HAAR \n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_7000_01_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 7000 -numStages 5 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType HAAR \n",
    "# LBP:\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_1750_01_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 5 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType LBP\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_3500_01_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 3500 -numStages 5 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType LBP \n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_7000_01_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 7000 -numStages 5 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType LBP \n",
    "\n",
    "\n",
    "# maxFalseAlarmRate = 0.05\n",
    "# Haar:\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_1750_005_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 5 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType HAAR\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_3500_005_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 3500 -numStages 5 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType HAAR \n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_7000_005_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 7000 -numStages 5 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType HAAR \n",
    "# LBP:\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_1750_005_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 5 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType LBP\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_3500_005_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 3500 -numStages 5 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType LBP \n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_7000_005_5/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 7000 -numStages 5 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType LBP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training für 7 Epochen:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxFalseAlarmRate = 0.1\n",
    "# Haar:\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_1750_01_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 7 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType HAAR\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_3500_01_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 3500 -numStages 7 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType HAAR \n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_7000_01_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 7000 -numStages 7 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType HAAR \n",
    "# LBP:\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_1750_01_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 7 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType LBP\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_3500_01_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 3500 -numStages 7 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType LBP \n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_7000_01_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 7000 -numStages 7 -maxFalseAlarmRate 0.1 -minHitRate 0.999 -featureType LBP \n",
    "\n",
    "\n",
    "# maxFalseAlarmRate = 0.05\n",
    "# Haar:\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_1750_005_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 7 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType HAAR\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_3500_005_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 3500 -numStages 7 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType HAAR \n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/HAAR_7000_005_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 7000 -numStages 7 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType HAAR \n",
    "# LBP:\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_1750_005_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 1750 -numStages 7 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType LBP\n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_3500_005_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 3500 -numStages 7 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType LBP \n",
    "!C:/Users/Dominik/Documents/opencv/build/x64/vc15/bin/opencv_traincascade.exe -data Dominik/models/LBP_7000_005_7/ -vec dataset/positive_samples/train/train.vec -bg dataset/negative_samples/neg2.txt -precalcValBufSize 16000 -precalcIdxBufSize 16000 -w 24 -h 24 -numPos 3500 -numNeg 7000 -numStages 7 -maxFalseAlarmRate 0.05 -minHitRate 0.999 -featureType LBP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation <a id=\"Evaluation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_from_file(cascade, output_folder, ground_truth_file):\n",
    "    with open(ground_truth_file, 'r') as gt_file:\n",
    "        gt_lines = gt_file.readlines()\n",
    "\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    actual_positives = 0\n",
    "\n",
    "    for line in gt_lines:\n",
    "        values = line.strip().split(' ')\n",
    "        image_name = values[0]\n",
    "        num_bounding_boxes = int(values[1])\n",
    "        bbox_values = list(map(int, values[2:]))\n",
    "        actual_positives += num_bounding_boxes\n",
    "        image_path = os.path.join('dataset/positive_samples/test/', image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Erkenne Geschwindigkeitsschilder\n",
    "        speed_signs = cascade.detectMultiScale(rgb, scaleFactor=1.1, minNeighbors=3, minSize=(24, 24))\n",
    "        # Extrahiere tatsächliche Bounding-Boxen\n",
    "        bboxes_gt = [bbox_values[i:i+4] for i in range(0, len(bbox_values), 4)]\n",
    "\n",
    "        # Vergleiche mit Ground Truth\n",
    "        for bbox_gt in bboxes_gt:\n",
    "            closest_sign = None\n",
    "            min_distance = float('inf')\n",
    "\n",
    "            for (cx, cy, w, h) in speed_signs:\n",
    "                distance = abs(cx - bbox_gt[0])\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_sign = (cx, cy, w, h)\n",
    "\n",
    "            if closest_sign is not None:\n",
    "                cx, cy, w, h = closest_sign\n",
    "                intersection = calculate_intersection([cx, cy, w, h], bbox_gt)\n",
    "                union = calculate_union([cx, cy, w, h], bbox_gt)\n",
    "                iou = intersection / union\n",
    "\n",
    "                if iou > 0.5:  # Schwellenwert für eine korrekte Erkennung\n",
    "                    true_positives += 1\n",
    "                else:\n",
    "                    false_positives += 1\n",
    "\n",
    "    false_negative = actual_positives - true_positives\n",
    "    true_negative = 0\n",
    "    # Print additional metrics (Precision, Recall, etc.)\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    print(f'Precision: {precision}, Recall: {recall}')\n",
    "\n",
    "    conf_matrix = np.array([[true_positives, false_positives],\n",
    "                       [false_negative, true_negative]])\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    labels = ['Positive', 'Negative']\n",
    "    categories = ['True Positive', 'False Positive', 'False Negative', 'True Negative']\n",
    "\n",
    "    sns.heatmap(conf_matrix, annot=np.array([[f'TP: {true_positives}', f'FP: {false_positives}'], [f'FN: {false_negative}', 'TN: Not available']]),\n",
    "                fmt='', cmap=\"Blues\", xticklabels=labels, yticklabels=labels, annot_kws={'size': 14})\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix (Number of ground truth data: {actual_positives})')\n",
    "    plt.show()\n",
    "\n",
    "def calculate_intersection(bbox1, bbox2):\n",
    "    x1, y1, w1, h1 = bbox1\n",
    "    x2, y2, w2, h2 = bbox2\n",
    "\n",
    "    x_intersection = max(0, min(x1 + w1, x2 + w2) - max(x1, x2))\n",
    "    y_intersection = max(0, min(y1 + h1, y2 + h2) - max(y1, y2))\n",
    "    return x_intersection * y_intersection\n",
    "\n",
    "def calculate_union(bbox1, bbox2):\n",
    "    x1, y1, w1, h1 = bbox1\n",
    "    x2, y2, w2, h2 = bbox2\n",
    "\n",
    "    area_bbox1 = w1 * h1\n",
    "    area_bbox2 = w2 * h2\n",
    "    intersection = calculate_intersection(bbox1, bbox2)\n",
    "    union = area_bbox1 + area_bbox2 - intersection\n",
    "    return union\n",
    "\n",
    "\n",
    "\n",
    "def test_speed(cascade):\n",
    "\n",
    "    # Pfad zum Bild, das du klassifizieren möchtest\n",
    "    image_path = r'dataset\\positive_samples\\test\\frame_2303.jpg'\n",
    "    image = cv2.imread(image_path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Messen der Zeit vor der Klassifikation\n",
    "    start_time = time.time()\n",
    "\n",
    "    objects = cascade.detectMultiScale(gray_image, scaleFactor=1.4, minNeighbors=5, minSize=(24, 24))\n",
    "\n",
    "    # Messen der Zeit nach der Klassifikation\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Recognised objects:\", len(objects))\n",
    "    print(\"Time for the localization: {:.4f} Seconds\".format(end_time - start_time))\n",
    "\n",
    "    for (x, y, w, h) in objects:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Detected Objects', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cascade_speedsign = cv2.CascadeClassifier('Dominik/models/cascade_15/cascade.xml')\n",
    "    if cascade_speedsign.empty():\n",
    "        print(\"Error: Unable to load cascade classifier.\")\n",
    "\n",
    "    output_folder_path = 'dataset/results4/'\n",
    "    ground_truth_file = r\"Dominik\\annotation_files\\test.txt\"\n",
    "\n",
    "    process_images_from_file(cascade_speedsign, output_folder_path, ground_truth_file)\n",
    "    test_speed(cascade_speedsign)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing <a id=\"Testing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Diskussion der Ergebnisse <a id=\"Diskussion\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
