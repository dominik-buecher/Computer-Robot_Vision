{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfade zu positiven und negativen Bildern\n",
    "positive_images_path = 'positive_images/'\n",
    "negative_images_path = 'negative_images/'\n",
    "\n",
    "# Pfad zum speichern des trainierten Modells\n",
    "cascade_model_path = 'trained_model.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainieren des Cascaden-Modells\n",
    "cv2.samples_create_samples_from_info(\n",
    "    'info.dat', positive_images_path, negative_images_path,\n",
    "    img_size=(50, 50), num_samples=1000, bg_color=(0, 0, 0),\n",
    "    invert=False, max_horizontal_shift=0, max_vertical_shift=0,\n",
    "    max_rotation_angle=0, max_scale_factor=0\n",
    ")\n",
    "\n",
    "cv2.traincascade(cv2.CascadeClassifier_create(), 'info.dat',\n",
    "                 'cascade_model.xml', numPos=1000, numNeg=500,\n",
    "                 numStages=20, minHitRate=0.999, maxFalseAlarmRate=0.5,\n",
    "                 stages=None, features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at models/Resnet152_model_adam.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dominik\\Documents\\Studium\\Master\\Computer_vision\\Computer-Robot_Vision\\Dominik\\train_location_model.ipynb Cell 4\u001b[0m line \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m model_path_InceptionV3_rmsprop \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels/InceptionV3_model_rmsprop.h5\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Select one of the eight pre-trained models, while keeping the remaining models commented out!\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m##############################################################################################\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# model = load_model(model_path_ResNet50_adam)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# model = load_model(model_path_ResNet50_rmsprop)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# model = load_model(model_path_ResNet101_adam)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# model = load_model(model_path_ResNet101_rmsprop)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(model_path_Resnet152_adam)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# model = load_model(model_path_Resnet152_rmsprop)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# model = load_model(model_path_InceptionV3_adam)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# model = load_model(model_path_InceptionV3_rmsprop)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m##############################################################################################\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Paths to the cascade file\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dominik/Documents/Studium/Master/Computer_vision/Computer-Robot_Vision/Dominik/train_location_model.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m face_cascade_path \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mhaarcascades \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhaarcascade_frontalface_default.xml\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\saving\\save.py:204\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    203\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 204\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    206\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    207\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(filepath_str, \u001b[39mcompile\u001b[39m, options)\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at models/Resnet152_model_adam.h5"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.applications import ResNet50, ResNet101, ResNet152, InceptionV3, VGG16\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageOps\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "cascade_speedsign = cv2.CascadeClassifier('cascade/cascade.xml')\n",
    "\n",
    "classes = { 0:'Dominik',  \n",
    "            1:'Unknown'}\n",
    "\n",
    "# Function to detect faces\n",
    "def detect_faces(image):\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cascade_speedsign.detectMultiScale(rgb, scaleFactor=1.2, minNeighbors=5, minSize=(30, 30))\n",
    "    return faces\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Check if the webcam is available\n",
    "if not cap.isOpened():\n",
    "    print(\"No webcam found or access denied.\")\n",
    "else:\n",
    "    # Infinite loop for face recognition\n",
    "    while True:\n",
    "        # Capture frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "        # Detect faces\n",
    "        faces = detect_faces(frame)\n",
    "\n",
    "        # Make predictions for each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            \n",
    "            # Expand the frame of the face\n",
    "            val = 40\n",
    "            x = max(0, x - val)\n",
    "            y = max(0, y - val)\n",
    "            w = min(frame.shape[1], val+x+w) - x\n",
    "            h = min(frame.shape[0], val+y+h) - y\n",
    "            face_image = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            #face_image = np.expand_dims(face_image, axis=0)\n",
    "            face_image = img_to_array(face_image)\n",
    "            # normalize the image\n",
    "            face_image = cv2.normalize(face_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            face_image = array_to_img(face_image)\n",
    "            face_image = face_image.resize((224, 224))\n",
    "            face_image = np.expand_dims(face_image, axis=0)\n",
    "            face_image = np.array(face_image)\n",
    "\n",
    "            # Perform face classification\n",
    "            # get the label from the highest prediction\n",
    "            predictions = np.argmax(model.predict(face_image), axis=1)[0]        \n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, classes[predictions], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "        # Exit the loop by pressing 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the webcam stream\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
